Model Name,Provider,Dataset,AA-LCR,τ²-Bench Telecom
Apriel-v1.5-15B-Thinker,ServiceNow,ServiceNow training dataset,20.00%,68.40%
Arctic Instruct,Snowflake,Snowflake training dataset,N/A,N/A
Aya Expanse 32B,Cohere,Cohere training dataset,10.70%,0.00%
Aya Expanse 8B,Cohere,Cohere training dataset,0.00%,0.00%
Codestral (May '24),Mistral,Mistral training dataset,N/A,N/A
Codestral-Mamba,Mistral,Mistral training dataset,N/A,N/A
Cogito v2.1 (Reasoning),Deep Cogito,Deep Cogito training dataset,21.70%,N/A
Command A,Cohere,Cohere training dataset,18.00%,15.20%
Command-R (Aug '24),Cohere,Cohere training dataset,N/A,N/A
Command-R (Mar '24),Cohere,Cohere training dataset,N/A,N/A
Command-R+ (Apr '24),Cohere,Cohere training dataset,N/A,N/A
Command-R+ (Aug '24),Cohere,Cohere training dataset,N/A,N/A
DBRX Instruct,Databricks,Databricks training dataset,N/A,N/A
DeepHermes 3 - Llama-3.1 8B Preview (Non-reasoning),Nous Research,Nous Research training dataset,N/A,N/A
DeepHermes 3 - Mistral 24B Preview (Non-reasoning),Nous Research,Nous Research training dataset,N/A,N/A
DeepSeek Coder V2 Lite Instruct,DeepSeek,DeepSeek training dataset,N/A,N/A
DeepSeek LLM 67B Chat (V1),DeepSeek,DeepSeek training dataset,N/A,N/A
DeepSeek R1 (Jan '25),DeepSeek,DeepSeek training dataset,52.30%,11.40%
DeepSeek R1 0528 (May '25),DeepSeek,DeepSeek training dataset,54.70%,36.50%
DeepSeek R1 0528 Qwen3 8B,DeepSeek,DeepSeek training dataset,13.00%,0.00%
DeepSeek R1 Distill Llama 70B,DeepSeek,DeepSeek training dataset,11.00%,21.90%
DeepSeek R1 Distill Llama 8B,DeepSeek,DeepSeek training dataset,0.00%,N/A
DeepSeek R1 Distill Qwen 1.5B,DeepSeek,DeepSeek training dataset,0.30%,N/A
DeepSeek R1 Distill Qwen 14B,DeepSeek,DeepSeek training dataset,7.00%,N/A
DeepSeek R1 Distill Qwen 32B,DeepSeek,DeepSeek training dataset,9.70%,N/A
DeepSeek V3 (Dec '24),DeepSeek,DeepSeek training dataset,29.00%,22.80%
DeepSeek V3 0324,DeepSeek,DeepSeek training dataset,41.00%,47.10%
DeepSeek V3.1 (Non-reasoning),DeepSeek,DeepSeek training dataset,45.00%,34.80%
DeepSeek V3.1 (Reasoning),DeepSeek,DeepSeek training dataset,53.30%,37.40%
DeepSeek V3.1 Terminus (Non-reasoning),DeepSeek,DeepSeek training dataset,43.30%,37.10%
DeepSeek V3.1 Terminus (Reasoning),DeepSeek,DeepSeek training dataset,65.00%,37.10%
DeepSeek V3.2 Exp (Non-reasoning),DeepSeek,DeepSeek training dataset,43.00%,33.90%
DeepSeek V3.2 Exp (Reasoning),DeepSeek,DeepSeek training dataset,69.00%,33.90%
DeepSeek-Coder-V2,DeepSeek,DeepSeek training dataset,N/A,N/A
DeepSeek-OCR,DeepSeek,DeepSeek training dataset,N/A,N/A
DeepSeek-V2-Chat,DeepSeek,DeepSeek training dataset,N/A,N/A
DeepSeek-V2.5,DeepSeek,DeepSeek training dataset,N/A,N/A
DeepSeek-V2.5 (Dec '24),DeepSeek,DeepSeek training dataset,N/A,N/A
Devstral Small (Jul '25),Mistral,Mistral training dataset,17.00%,28.40%
Devstral Small (May '25),Mistral,Mistral training dataset,N/A,N/A
Doubao Seed Code,ByteDance Seed,ByteDance Seed training dataset,65.30%,58.20%
ERNIE 4.5 300B A47B,Baidu,Baidu training dataset,2.30%,0.00%
EXAONE 4.0 32B (Non-reasoning),LG AI Research,LG AI Research training dataset,8.00%,4.10%
EXAONE 4.0 32B (Reasoning),LG AI Research,LG AI Research training dataset,14.00%,17.30%
Exaone 4.0 1.2B (Non-reasoning),LG AI Research,LG AI Research training dataset,0.00%,20.50%
Exaone 4.0 1.2B (Reasoning),LG AI Research,LG AI Research training dataset,0.00%,16.40%
GLM-4.5 (Reasoning),Z AI,Z AI training dataset,48.30%,43.00%
GLM-4.5-Air,Z AI,Z AI training dataset,43.70%,46.50%
GLM-4.5V (Non-reasoning),Z AI,Z AI training dataset,0.00%,19.60%
GLM-4.5V (Reasoning),Z AI,Z AI training dataset,0.00%,22.50%
GLM-4.6 (Non-reasoning),Z AI,Z AI training dataset,26.30%,76.90%
GLM-4.6 (Reasoning),Z AI,Z AI training dataset,54.30%,70.50%
Gemma 2 27B,Google,Google training dataset,N/A,N/A
Gemma 2 9B,Google,Google training dataset,N/A,N/A
Gemma 3 12B Instruct,Google,Google training dataset,6.70%,10.80%
Gemma 3 1B Instruct,Google,Google training dataset,0.00%,0.00%
Gemma 3 270M,Google,Google training dataset,0.00%,9.10%
Gemma 3 27B Instruct,Google,Google training dataset,5.70%,10.50%
Gemma 3 4B Instruct,Google,Google training dataset,5.70%,5.00%
Gemma 3n E2B Instruct,Google,Google training dataset,0.00%,0.00%
Gemma 3n E4B Instruct,Google,Google training dataset,0.00%,5.00%
Granite 3.3 8B (Non-reasoning),IBM,IBM training dataset,4.30%,10.50%
Granite 4.0 1B,IBM,IBM training dataset,4.00%,22.80%
Granite 4.0 350M,IBM,IBM training dataset,0.00%,13.20%
Granite 4.0 H 1B,IBM,IBM training dataset,6.30%,19.60%
Granite 4.0 H 350M,IBM,IBM training dataset,0.00%,14.60%
Granite 4.0 H Small,IBM,IBM training dataset,9.00%,17.30%
Granite 4.0 Micro,IBM,IBM training dataset,4.00%,12.60%
Grok 2 (Dec '24),xAI,xAI training dataset,N/A,N/A
Grok-1,xAI,xAI training dataset,N/A,N/A
Hermes 3 - Llama-3.1 70B,Nous Research,Nous Research training dataset,N/A,N/A
Hermes 4 - Llama-3.1 405B (Non-reasoning),Nous Research,Nous Research training dataset,20.00%,26.60%
Hermes 4 - Llama-3.1 405B (Reasoning),Nous Research,Nous Research training dataset,20.70%,22.20%
Hermes 4 - Llama-3.1 70B (Non-reasoning),Nous Research,Nous Research training dataset,2.00%,21.60%
Hermes 4 - Llama-3.1 70B (Reasoning),Nous Research,Nous Research training dataset,6.70%,22.50%
Jamba 1.6 Large,AI21 Labs,AI21 Labs training dataset,N/A,N/A
Jamba 1.6 Mini,AI21 Labs,AI21 Labs training dataset,N/A,N/A
Jamba 1.7 Large,AI21 Labs,AI21 Labs training dataset,17.30%,13.50%
Jamba 1.7 Mini,AI21 Labs,AI21 Labs training dataset,12.70%,12.60%
Jamba Reasoning 3B,AI21 Labs,AI21 Labs training dataset,7.00%,15.80%
Kimi K2,Moonshot AI,Moonshot AI training dataset,51.00%,61.10%
Kimi K2 0905,Moonshot AI,Moonshot AI training dataset,52.30%,73.40%
Kimi K2 Thinking,Moonshot AI,Moonshot AI training dataset,66.30%,93.00%
Kimi Linear 48B A3B Instruct,Moonshot AI,Moonshot AI training dataset,25.70%,N/A
LFM 40B,Liquid AI,Liquid AI training dataset,N/A,N/A
LFM2 1.2B,Liquid AI,Liquid AI training dataset,0.00%,12.60%
LFM2 2.6B,Liquid AI,Liquid AI training dataset,0.00%,13.50%
LFM2 8B A1B,Liquid AI,Liquid AI training dataset,0.00%,10.50%
Ling-1T,InclusionAI,InclusionAI training dataset,34.70%,32.70%
Ling-flash-2.0,InclusionAI,InclusionAI training dataset,15.00%,20.80%
Ling-mini-2.0,InclusionAI,InclusionAI training dataset,6.70%,13.20%
Llama 2 Chat 13B,Meta,Meta training dataset,N/A,N/A
Llama 2 Chat 70B,Meta,Meta training dataset,N/A,N/A
Llama 2 Chat 7B,Meta,Meta training dataset,N/A,N/A
Llama 3 Instruct 70B,Meta,Meta training dataset,N/A,N/A
Llama 3 Instruct 8B,Meta,Meta training dataset,N/A,N/A
Llama 3.1 Instruct 405B,Meta,Meta training dataset,24.30%,19.00%
Llama 3.1 Instruct 70B,Meta,Meta training dataset,6.30%,15.20%
Llama 3.1 Instruct 8B,Meta,Meta training dataset,15.70%,16.40%
Llama 3.1 Nemotron Instruct 70B,NVIDIA,NVIDIA training dataset,7.00%,23.10%
Llama 3.1 Nemotron Nano 4B v1.1 (Reasoning),NVIDIA,NVIDIA training dataset,0.00%,11.70%
Llama 3.1 Nemotron Ultra 253B v1 (Reasoning),NVIDIA,NVIDIA training dataset,7.30%,11.40%
Llama 3.1 Tulu3 405B,Allen Institute for AI,Allen Institute for AI training dataset,N/A,N/A
Llama 3.2 Instruct 11B (Vision),Meta,Meta training dataset,11.70%,14.60%
Llama 3.2 Instruct 1B,Meta,Meta training dataset,5.00%,12.30%
Llama 3.2 Instruct 3B,Meta,Meta training dataset,2.00%,21.10%
Llama 3.2 Instruct 90B (Vision),Meta,Meta training dataset,N/A,N/A
Llama 3.3 Instruct 70B,Meta,Meta training dataset,15.00%,26.60%
Llama 3.3 Nemotron Super 49B v1 (Non-reasoning),NVIDIA,NVIDIA training dataset,11.30%,N/A
Llama 3.3 Nemotron Super 49B v1 (Reasoning),NVIDIA,NVIDIA training dataset,17.00%,N/A
Llama 4 Maverick,Meta,Meta training dataset,46.00%,17.80%
Llama 4 Scout,Meta,Meta training dataset,25.80%,15.50%
Llama Nemotron Super 49B v1.5 (Non-reasoning),NVIDIA,NVIDIA training dataset,22.00%,25.10%
Llama Nemotron Super 49B v1.5 (Reasoning),NVIDIA,NVIDIA training dataset,34.00%,28.10%
Magistral Medium 1.2,Mistral,Mistral training dataset,51.30%,52.00%
Magistral Small 1.2,Mistral,Mistral training dataset,16.30%,27.80%
MiniMax M1 40k,MiniMax,MiniMax training dataset,51.70%,31.60%
MiniMax M1 80k,MiniMax,MiniMax training dataset,54.30%,34.20%
MiniMax-M2,MiniMax,MiniMax training dataset,61.00%,86.80%
MiniMax-Text-01,MiniMax,MiniMax training dataset,33.00%,15.50%
Ministral 8B,Mistral,Mistral training dataset,7.70%,0.00%
Mistral 7B Instruct,Mistral,Mistral training dataset,N/A,N/A
Mistral Large 2 (Jul '24),Mistral,Mistral training dataset,1.70%,33.00%
Mistral Large 2 (Nov '24),Mistral,Mistral training dataset,5.30%,30.70%
Mistral Medium 3.1,Mistral,Mistral training dataset,19.70%,40.60%
Mistral NeMo,Mistral,Mistral training dataset,N/A,N/A
Mistral Small (Sep '24),Mistral,Mistral training dataset,N/A,N/A
Mistral Small 3,Mistral,Mistral training dataset,0.00%,19.60%
Mistral Small 3.1,Mistral,Mistral training dataset,13.70%,N/A
Mistral Small 3.2,Mistral,Mistral training dataset,17.30%,29.50%
Mixtral 8x22B Instruct,Mistral,Mistral training dataset,N/A,N/A
Mixtral 8x7B Instruct,Mistral,Mistral training dataset,N/A,N/A
Molmo 7B-D,Allen Institute for AI,Allen Institute for AI training dataset,0.00%,0.00%
NVIDIA Nemotron Nano 9B V2 (Non-reasoning),NVIDIA,NVIDIA training dataset,22.70%,23.40%
NVIDIA Nemotron Nano 9B V2 (Reasoning),NVIDIA,NVIDIA training dataset,21.00%,21.90%
OLMo 2 32B,Allen Institute for AI,Allen Institute for AI training dataset,0.00%,0.00%
OLMo 2 7B,Allen Institute for AI,Allen Institute for AI training dataset,0.00%,0.00%
OpenChat 3.5 (1210),OpenChat,OpenChat training dataset,N/A,N/A
Phi-3 Medium Instruct 14B,Microsoft Azure,Microsoft Azure training dataset,3.00%,0.00%
Phi-3 Mini Instruct 3.8B,Microsoft Azure,Microsoft Azure training dataset,2.00%,0.00%
Phi-4,Microsoft Azure,Microsoft Azure training dataset,0.00%,0.00%
Phi-4 Mini Instruct,Microsoft Azure,Microsoft Azure training dataset,13.70%,8.20%
Phi-4 Multimodal Instruct,Microsoft Azure,Microsoft Azure training dataset,N/A,N/A
Pixtral 12B (2409),Mistral,Mistral training dataset,N/A,N/A
Pixtral Large,Mistral,Mistral training dataset,10.30%,36.50%
QwQ 32B,Alibaba,Alibaba training dataset,25.00%,N/A
Qwen2.5 Coder Instruct 32B,Alibaba,Alibaba training dataset,N/A,N/A
Qwen2.5 Coder Instruct 7B ,Alibaba,Alibaba training dataset,N/A,N/A
Qwen2.5 Instruct 32B,Alibaba,Alibaba training dataset,N/A,N/A
Qwen2.5 Instruct 72B,Alibaba,Alibaba training dataset,20.30%,34.50%
Qwen2.5 Max,Alibaba,Alibaba training dataset,N/A,N/A
Qwen2.5 Turbo,Alibaba,Alibaba training dataset,N/A,N/A
Qwen3 0.6B (Non-reasoning),Alibaba,Alibaba training dataset,0.00%,14.60%
Qwen3 0.6B (Reasoning),Alibaba,Alibaba training dataset,0.00%,21.10%
Qwen3 1.7B (Non-reasoning),Alibaba,Alibaba training dataset,0.00%,21.60%
Qwen3 1.7B (Reasoning),Alibaba,Alibaba training dataset,0.00%,26.00%
Qwen3 14B (Non-reasoning),Alibaba,Alibaba training dataset,0.00%,32.20%
Qwen3 14B (Reasoning),Alibaba,Alibaba training dataset,0.00%,34.50%
Qwen3 235B A22B (Non-reasoning),Alibaba,Alibaba training dataset,0.00%,27.20%
Qwen3 235B A22B (Reasoning),Alibaba,Alibaba training dataset,0.00%,24.00%
Qwen3 235B A22B 2507 (Reasoning),Alibaba,Alibaba training dataset,67.00%,53.20%
Qwen3 235B A22B 2507 Instruct,Alibaba,Alibaba training dataset,31.20%,33.30%
Qwen3 30B A3B (Non-reasoning),Alibaba,Alibaba training dataset,0.00%,N/A
Qwen3 30B A3B (Reasoning),Alibaba,Alibaba training dataset,0.00%,26.00%
Qwen3 30B A3B 2507 (Reasoning),Alibaba,Alibaba training dataset,59.00%,28.10%
Qwen3 30B A3B 2507 Instruct,Alibaba,Alibaba training dataset,22.70%,10.20%
Qwen3 32B (Non-reasoning),Alibaba,Alibaba training dataset,0.00%,N/A
Qwen3 32B (Reasoning),Alibaba,Alibaba training dataset,0.00%,29.80%
Qwen3 4B (Non-reasoning),Alibaba,Alibaba training dataset,N/A,N/A
Qwen3 4B (Reasoning),Alibaba,Alibaba training dataset,0.00%,19.00%
Qwen3 4B 2507 (Reasoning),Alibaba,Alibaba training dataset,37.70%,25.40%
Qwen3 4B 2507 Instruct,Alibaba,Alibaba training dataset,7.30%,26.60%
Qwen3 8B (Non-reasoning),Alibaba,Alibaba training dataset,0.00%,24.90%
Qwen3 8B (Reasoning),Alibaba,Alibaba training dataset,0.00%,27.80%
Qwen3 Coder 30B A3B Instruct,Alibaba,Alibaba training dataset,29.00%,34.50%
Qwen3 Coder 480B A35B Instruct,Alibaba,Alibaba training dataset,42.30%,43.60%
Qwen3 Max,Alibaba,Alibaba training dataset,46.70%,74.30%
Qwen3 Max Thinking,Alibaba,Alibaba training dataset,57.70%,83.60%
Qwen3 Next 80B A3B (Reasoning),Alibaba,Alibaba training dataset,60.30%,41.50%
Qwen3 Next 80B A3B Instruct,Alibaba,Alibaba training dataset,51.30%,21.60%
Qwen3 Omni 30B A3B (Reasoning),Alibaba,Alibaba training dataset,0.00%,21.30%
Qwen3 Omni 30B A3B Instruct,Alibaba,Alibaba training dataset,0.00%,16.40%
Qwen3 VL 235B A22B (Reasoning),Alibaba,Alibaba training dataset,58.70%,54.10%
Qwen3 VL 235B A22B Instruct,Alibaba,Alibaba training dataset,31.70%,35.10%
Qwen3 VL 30B A3B (Reasoning),Alibaba,Alibaba training dataset,40.70%,19.90%
Qwen3 VL 30B A3B Instruct,Alibaba,Alibaba training dataset,23.70%,19.00%
Qwen3 VL 32B (Reasoning),Alibaba,Alibaba training dataset,55.30%,45.60%
Qwen3 VL 32B Instruct,Alibaba,Alibaba training dataset,31.30%,29.20%
Qwen3 VL 4B (Reasoning),Alibaba,Alibaba training dataset,21.30%,15.50%
Qwen3 VL 4B Instruct,Alibaba,Alibaba training dataset,13.00%,23.40%
Qwen3 VL 8B (Reasoning),Alibaba,Alibaba training dataset,31.00%,22.50%
Qwen3 VL 8B Instruct,Alibaba,Alibaba training dataset,15.30%,29.20%
R1 1776,Perplexity,Perplexity training dataset,N/A,N/A
Reka Flash 3,Reka AI,Reka AI training dataset,0.00%,0.00%
Ring-1T,InclusionAI,InclusionAI training dataset,0.00%,26.30%
Ring-flash-2.0,InclusionAI,InclusionAI training dataset,21.00%,0.00%
Seed-OSS-36B-Instruct,ByteDance Seed,ByteDance Seed training dataset,57.70%,49.40%
Solar Mini,Upstage,Upstage training dataset,N/A,20.20%
Solar Pro 2 (Non-reasoning),Upstage,Upstage training dataset,0.00%,31.90%
Solar Pro 2 (Reasoning),Upstage,Upstage training dataset,0.00%,28.10%
gpt-oss-120B (high),OpenAI,OpenAI training dataset,50.70%,65.80%
gpt-oss-120B (low),OpenAI,OpenAI training dataset,43.70%,45.00%
gpt-oss-20B (high),OpenAI,OpenAI training dataset,34.30%,60.20%
gpt-oss-20B (low),OpenAI,OpenAI training dataset,31.00%,50.30%
