# Best Models CSV Files - Explained

## What Are These Files?

All `best_models_*.csv` files are **OUTPUT files** generated by the semantic matching system. They are temporary results that can be regenerated anytime.

## How They're Created

These files are generated when you run:
- `get_best_models_semantic.py` 
- `test_usecase_interactive.py`
- `test_usecase_simple.py`

## What They're Based On

Each `best_models_*.csv` file is based on one or more of the **9 predefined use case CSVs**:

### Source Files (These are the REAL data):
1. `opensource_chatbot_conversational.csv`
2. `opensource_code_completion.csv`
3. `opensource_code_generation_detailed.csv`
4. `opensource_translation.csv`
5. `opensource_content_generation.csv`
6. `opensource_summarization_short.csv`
7. `opensource_document_analysis_rag.csv`
8. `opensource_long_document_summarization.csv`
9. `opensource_research_legal_analysis.csv`

### Example: `best_models_rag_test.csv`

**Based on**: `opensource_document_analysis_rag.csv`

**How it was created**:
1. User provided description: "I need RAG for document question answering"
2. System calculated semantic similarity
3. Matched to `document_analysis_rag` use case (high similarity)
4. Loaded `opensource_document_analysis_rag.csv`
5. Saved as `best_models_rag_test.csv`

**Result**: Same models as `opensource_document_analysis_rag.csv`, just renamed

### Example: `best_models_mixed_task.csv`

**Based on**: Multiple use case CSVs combined

**How it was created**:
1. User provided: "I need a chatbot that can also help with code completion"
2. System matched to:
   - `chatbot_conversational` (57.8%)
   - `code_completion` (54.9%)
   - `code_generation_detailed` (40.6%)
3. Loaded all three CSVs
4. Combined with weighted scores
5. Saved as `best_models_mixed_task.csv`

**Result**: Weighted combination of multiple use cases

## Current Output Files

| File | Based On | Type |
|------|----------|------|
| `best_models_code_completion.csv` | `opensource_code_completion.csv` | Direct copy |
| `best_models_code_autocomplete.csv` | `opensource_code_completion.csv` + others | Combined |
| `best_models_document_qa.csv` | `opensource_document_analysis_rag.csv` + others | Combined |
| `best_models_doc_qa_test.csv` | `opensource_document_analysis_rag.csv` + others | Combined |
| `best_models_rag_test.csv` | `opensource_document_analysis_rag.csv` | Direct copy |
| `best_models_mixed_task.csv` | Multiple use cases | Combined |
| `best_models_my_custom_use_case.csv` | Various (depends on description) | Combined |

## Key Points

1. **All `best_models_*.csv` files are OUTPUT files** - They can be deleted
2. **They're based on the 9 predefined use case CSVs** - Which are the source of truth
3. **They can be regenerated** - Just run the semantic matching again
4. **They're temporary** - Created during testing/usage

## Cleanup Recommendation

**Delete all `best_models_*.csv` files** - They're just test outputs and can be regenerated.

**Keep the 9 predefined use case CSVs** - These are the source files.

## How to Regenerate

If you need any of these files again, just run:

```bash
# For a specific use case
python3 get_best_models_semantic.py --json '{"use_case": {"type": "custom", "name": "rag_test", "description": "I need RAG for document question answering"}}'
```

## Data Flow

```
9 Predefined Use Case CSVs (SOURCE)
    ‚Üì
Semantic Matching System
    ‚Üì
best_models_*.csv (OUTPUT - can delete)
```

## Summary

- ‚úÖ **Keep**: 9 `opensource_*_*.csv` files (use case CSVs)
- ‚ùå **Delete**: All `best_models_*.csv` files (output files)
- üîÑ **Regenerate**: Run semantic matching when needed

