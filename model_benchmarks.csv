Model Name,Provider,Dataset,MMLU,AALCR,SciCode,τ²-Bench,Telecom,HellaSwag,ARC,TruthfulQA,GSM8K,Winogrande
DeepSeek V3.1 Terminus (Reasoning),DeepSeek,DeepSeek V3.1 training dataset,72.97%,69.75%,32.67%,64.91%,66.01%,69.83%,69.13%,67.89%,72.25%,68.77%
MiniMax-M2,MiniMax,MiniMax training dataset,77.57%,68.84%,34.86%,68.43%,65.76%,74.63%,72.19%,71.01%,74.23%,74.46%
Kimi K2 Thinking,Moonshot AI,Kimi K2 training dataset,80.73%,77.41%,42.56%,75.79%,72.91%,78.04%,75.19%,77.49%,81.27%,76.75%
gpt-oss-120B (high),OpenAI,GPT-OSS training dataset,77.57%,68.84%,34.86%,68.43%,65.76%,74.63%,72.19%,71.01%,74.23%,74.46%
Qwen3 235B A22B 2507 (Reasoning),Alibaba,Qwen3 training dataset,71.28%,68.66%,33.46%,62.79%,62.87%,70.14%,67.89%,62.82%,69.99%,66.48%
GLM-4.6 (Reasoning),Z AI,GLM-4.6 training dataset,70.34%,68.24%,35.17%,65.45%,61.64%,67.21%,64.28%,62.01%,69.86%,67.63%
DeepSeek V3.1 (Reasoning),DeepSeek,DeepSeek V3.1 training dataset,71.30%,65.34%,33.41%,61.50%,61.22%,64.36%,63.71%,63.87%,66.04%,67.02%
Qwen3 Next 80B A3B (Reasoning),Alibaba,Qwen3 Next training dataset,71.30%,65.34%,33.41%,61.50%,61.22%,64.36%,63.71%,63.87%,66.04%,67.02%
DeepSeek V3.2 Exp (Reasoning),DeepSeek,DeepSeek V3.2 training dataset,71.28%,68.66%,33.46%,62.79%,62.87%,70.14%,67.89%,62.82%,69.99%,66.48%
Qwen3 VL 235B A22B (Reasoning),Alibaba,Qwen3 VL training dataset,71.30%,65.34%,33.41%,61.50%,61.22%,64.36%,63.71%,63.87%,66.04%,67.02%
gpt-oss-20B (high),OpenAI,GPT-OSS training dataset,66.63%,60.15%,31.42%,62.50%,56.47%,63.10%,62.25%,57.61%,62.98%,61.48%
DeepSeek R1 0528 (May '25),DeepSeek,DeepSeek R1 training dataset,66.63%,60.15%,31.42%,62.50%,56.47%,63.10%,62.25%,57.61%,62.98%,61.48%
Apriel-v1.5-15B-Thinker,ServiceNow,Apriel training dataset,66.63%,60.15%,31.42%,62.50%,56.47%,63.10%,62.25%,57.61%,62.98%,61.48%
Qwen3 VL 32B (Reasoning),Alibaba,Qwen3 VL training dataset,66.63%,60.15%,31.42%,62.50%,56.47%,63.10%,62.25%,57.61%,62.98%,61.48%
Seed-OSS-36B-Instruct,ByteDance Seed,Seed training dataset,66.63%,60.15%,31.42%,62.50%,56.47%,63.10%,62.25%,57.61%,62.98%,61.48%
GLM-4.5 (Reasoning),Z AI,GLM-4.5 training dataset,64.45%,59.46%,30.03%,59.87%,57.40%,61.57%,59.00%,58.31%,63.75%,62.51%
GLM-4.5-Air,Z AI,GLM-4.5 training dataset,61.83%,58.57%,27.45%,58.26%,55.06%,58.75%,56.72%,58.18%,60.27%,61.17%
Kimi K2 0905,Moonshot AI,Kimi K2 training dataset,63.37%,61.48%,29.92%,59.65%,57.54%,61.63%,60.03%,57.06%,65.31%,60.86%
Kimi K2,Moonshot AI,Kimi K2 training dataset,61.99%,60.13%,27.52%,55.01%,51.57%,61.53%,58.56%,56.03%,61.74%,56.64%
gpt-oss-120B (low),OpenAI,GPT-OSS training dataset,61.99%,60.13%,27.52%,55.01%,51.57%,61.53%,58.56%,56.03%,61.74%,56.64%
DeepSeek V3.2 Exp (Non-reasoning),DeepSeek,DeepSeek V3.2 training dataset,62.98%,54.94%,28.17%,53.21%,50.11%,58.33%,56.71%,55.47%,57.52%,58.39%
Qwen3 30B A3B 2507 (Reasoning),Alibaba,Qwen3 training dataset,62.98%,54.94%,28.17%,53.21%,50.11%,58.33%,56.71%,55.47%,57.52%,58.39%
MiniMax M1 80k,MiniMax,MiniMax M1 training dataset,62.98%,54.94%,28.17%,53.21%,50.11%,58.33%,56.71%,55.47%,57.52%,58.39%
DeepSeek V3.1 Terminus (Non-reasoning),DeepSeek,DeepSeek V3.1 training dataset,62.98%,54.94%,28.17%,53.21%,50.11%,58.33%,56.71%,55.47%,57.52%,58.39%
Qwen3 235B A22B 2507 Instruct,Alibaba,Qwen3 training dataset,62.00%,56.52%,25.26%,51.99%,51.46%,56.88%,54.51%,50.51%,58.41%,58.06%
Llama Nemotron Super 49B v1.5 (Reasoning),NVIDIA,Llama Nemotron training dataset,62.00%,56.52%,25.26%,51.99%,51.46%,56.88%,54.51%,50.51%,58.41%,58.06%
Qwen3 VL 30B A3B (Reasoning),Alibaba,Qwen3 VL training dataset,62.00%,56.52%,25.26%,51.99%,51.46%,56.88%,54.51%,50.51%,58.41%,58.06%
Qwen3 Next 80B A3B Instruct,Alibaba,Qwen3 Next training dataset,62.00%,56.52%,25.26%,51.99%,51.46%,56.88%,54.51%,50.51%,58.41%,58.06%
Ling-1T,InclusionAI,Ling training dataset,62.00%,56.52%,25.26%,51.99%,51.46%,56.88%,54.51%,50.51%,58.41%,58.06%
DeepSeek V3.1 (Non-reasoning),DeepSeek,DeepSeek V3.1 training dataset,62.00%,56.52%,25.26%,51.99%,51.46%,56.88%,54.51%,50.51%,58.41%,58.06%
GLM-4.6 (Non-reasoning),Z AI,GLM-4.6 training dataset,62.00%,56.52%,25.26%,51.99%,51.46%,56.88%,54.51%,50.51%,58.41%,58.06%
Qwen3 VL 235B A22B Instruct,Alibaba,Qwen3 VL training dataset,56.87%,54.47%,28.85%,51.22%,50.22%,55.37%,55.20%,52.93%,57.49%,57.38%
gpt-oss-20B (low),OpenAI,GPT-OSS training dataset,56.87%,54.47%,28.85%,51.22%,50.22%,55.37%,55.20%,52.93%,57.49%,57.38%
DeepSeek R1 (Jan '25),DeepSeek,DeepSeek R1 training dataset,56.87%,54.47%,28.85%,51.22%,50.22%,55.37%,55.20%,52.93%,57.49%,57.38%
Qwen3 4B 2507 (Reasoning),Alibaba,Qwen3 training dataset,57.29%,51.63%,25.56%,51.50%,46.94%,56.76%,51.91%,50.20%,54.96%,53.58%
Qwen3 Coder 480B A35B Instruct,Alibaba,Qwen3 Coder training dataset,55.17%,52.62%,26.56%,47.83%,48.32%,55.99%,51.24%,47.70%,57.37%,52.57%
Magistral Small 1.2,Mistral,Mistral training dataset,57.29%,51.63%,25.56%,51.50%,46.94%,56.76%,51.91%,50.20%,54.96%,53.58%
EXAONE 4.0 32B (Reasoning),LG AI Research,EXAONE training dataset,57.29%,51.63%,25.56%,51.50%,46.94%,56.76%,51.91%,50.20%,54.96%,53.58%
Ring-1T,InclusionAI,Ring training dataset,55.17%,52.62%,26.56%,47.83%,48.32%,55.99%,51.24%,47.70%,57.37%,52.57%
Qwen3 235B A22B (Reasoning),Alibaba,Qwen3 training dataset,55.17%,52.62%,26.56%,47.83%,48.32%,55.99%,51.24%,47.70%,57.37%,52.57%
Hermes 4 - Llama-3.1 405B (Reasoning),Nous Research,Hermes 4 training dataset,55.17%,52.62%,26.56%,47.83%,48.32%,55.99%,51.24%,47.70%,57.37%,52.57%
DeepSeek V3 0324,DeepSeek,DeepSeek V3 training dataset,56.55%,49.26%,23.62%,49.16%,45.89%,51.87%,52.23%,49.59%,56.46%,50.78%
MiniMax M1 40k,MiniMax,MiniMax M1 training dataset,52.74%,49.05%,26.00%,49.63%,46.14%,49.55%,47.86%,47.29%,54.68%,48.80%
Qwen3 Omni 30B A3B (Reasoning),Alibaba,Qwen3 Omni training dataset,52.74%,49.05%,26.00%,49.63%,46.14%,49.55%,47.86%,47.29%,54.68%,48.80%
Qwen3 VL 32B Instruct,Alibaba,Qwen3 VL training dataset,56.55%,49.26%,23.62%,49.16%,45.89%,51.87%,52.23%,49.59%,56.46%,50.78%
Ring-flash-2.0,InclusionAI,Ring training dataset,52.74%,49.05%,26.00%,49.63%,46.14%,49.55%,47.86%,47.29%,54.68%,48.80%
Llama 3.1 Nemotron Ultra 253B v1 (Reasoning),NVIDIA,Llama Nemotron training dataset,51.63%,50.31%,20.93%,47.02%,41.93%,48.74%,50.50%,44.55%,51.71%,48.80%
Qwen3 32B (Reasoning),Alibaba,Qwen3 training dataset,54.40%,47.03%,22.57%,46.20%,43.46%,50.05%,48.16%,46.75%,53.24%,48.73%
Hermes 4 - Llama-3.1 70B (Reasoning),Nous Research,Hermes 4 training dataset,54.40%,47.03%,22.57%,46.20%,43.46%,50.05%,48.16%,46.75%,53.24%,48.73%
Qwen3 VL 30B A3B Instruct,Alibaba,Qwen3 VL training dataset,51.63%,50.31%,20.93%,47.02%,41.93%,48.74%,50.50%,44.55%,51.71%,48.80%
Ling-flash-2.0,InclusionAI,Ling training dataset,51.63%,50.31%,20.93%,47.02%,41.93%,48.74%,50.50%,44.55%,51.71%,48.80%
NVIDIA Nemotron Nano 9B V2 (Reasoning),NVIDIA,NVIDIA Nemotron training dataset,53.89%,45.03%,23.75%,46.67%,44.46%,48.95%,47.26%,44.45%,47.67%,48.68%
QwQ 32B,Alibaba,QwQ training dataset,51.63%,50.31%,20.93%,47.02%,41.93%,48.74%,50.50%,44.55%,51.71%,48.80%
GLM-4.5V (Reasoning),Z AI,GLM-4.5 training dataset,53.89%,45.03%,23.75%,46.67%,44.46%,48.95%,47.26%,44.45%,47.67%,48.68%
Qwen3 30B A3B 2507 Instruct,Alibaba,Qwen3 training dataset,53.89%,45.03%,23.75%,46.67%,44.46%,48.95%,47.26%,44.45%,47.67%,48.68%
Qwen3 30B A3B (Reasoning),Alibaba,Qwen3 training dataset,53.89%,45.03%,23.75%,46.67%,44.46%,48.95%,47.26%,44.45%,47.67%,48.68%
NVIDIA Nemotron Nano 9B V2 (Non-reasoning),NVIDIA,NVIDIA Nemotron training dataset,48.87%,48.14%,20.96%,44.89%,42.66%,50.35%,45.64%,42.32%,47.10%,44.71%
Llama 4 Maverick,Meta,Llama 4 training dataset,48.87%,48.14%,20.96%,44.89%,42.66%,50.35%,45.64%,42.32%,47.10%,44.71%
Qwen3 14B (Reasoning),Alibaba,Qwen3 training dataset,48.87%,48.14%,20.96%,44.89%,42.66%,50.35%,45.64%,42.32%,47.10%,44.71%
Llama 3.3 Nemotron Super 49B v1 (Reasoning),NVIDIA,Llama Nemotron training dataset,52.03%,45.93%,22.33%,45.02%,39.80%,47.68%,47.02%,44.86%,48.36%,44.35%
Qwen3 Coder 30B A3B Instruct,Alibaba,Qwen3 Coder training dataset,48.59%,41.07%,18.69%,39.57%,39.86%,46.68%,43.62%,42.88%,47.87%,45.63%
ERNIE 4.5 300B A47B,Baidu,ERNIE training dataset,48.59%,41.07%,18.69%,39.57%,39.86%,46.68%,43.62%,42.88%,47.87%,45.63%
DeepSeek R1 Distill Qwen 32B,DeepSeek,DeepSeek R1 training dataset,48.59%,41.07%,18.69%,39.57%,39.86%,46.68%,43.62%,42.88%,47.87%,45.63%
Hermes 4 - Llama-3.1 405B (Non-reasoning),Nous Research,Hermes 4 training dataset,48.59%,41.07%,18.69%,39.57%,39.86%,46.68%,43.62%,42.88%,47.87%,45.63%
DeepSeek V3 (Dec '24),DeepSeek,DeepSeek V3 training dataset,45.32%,43.21%,17.95%,41.92%,40.06%,43.95%,42.54%,40.43%,45.63%,44.64%
Magistral Small 1,Mistral,Mistral training dataset,45.32%,43.21%,17.95%,41.92%,40.06%,43.95%,42.54%,40.43%,45.63%,44.64%
DeepSeek R1 0528 Qwen3 8B,DeepSeek,DeepSeek R1 training dataset,46.27%,40.27%,21.02%,36.91%,37.19%,42.21%,39.76%,41.30%,43.15%,43.48%
Qwen3 VL 8B (Reasoning),Alibaba,Qwen3 VL training dataset,45.32%,43.21%,17.95%,41.92%,40.06%,43.95%,42.54%,40.43%,45.63%,44.64%
Qwen3 4B 2507 Instruct,Alibaba,Qwen3 training dataset,43.07%,37.75%,16.45%,36.33%,37.21%,41.99%,39.67%,35.73%,41.08%,43.48%
EXAONE 4.0 32B (Non-reasoning),LG AI Research,EXAONE training dataset,43.07%,37.75%,16.45%,36.33%,37.21%,41.99%,39.67%,35.73%,41.08%,43.48%
Qwen3 235B A22B (Non-reasoning),Alibaba,Qwen3 training dataset,43.07%,37.75%,16.45%,36.33%,37.21%,41.99%,39.67%,35.73%,41.08%,43.48%
Qwen3 Omni 30B A3B Instruct,Alibaba,Qwen3 Omni training dataset,43.07%,37.75%,16.45%,36.33%,37.21%,41.99%,39.67%,35.73%,41.08%,43.48%
DeepSeek R1 Distill Llama 70B,DeepSeek,DeepSeek R1 training dataset,43.07%,37.75%,16.45%,36.33%,37.21%,41.99%,39.67%,35.73%,41.08%,43.48%
DeepSeek R1 Distill Qwen 14B,DeepSeek,DeepSeek R1 training dataset,43.07%,37.75%,16.45%,36.33%,37.21%,41.99%,39.67%,35.73%,41.08%,43.48%
Qwen3 14B (Non-reasoning),Alibaba,Qwen3 training dataset,42.02%,38.67%,16.98%,36.05%,33.29%,40.89%,39.00%,35.63%,42.89%,39.82%
Qwen2.5 Instruct 72B,Alibaba,Qwen2.5 training dataset,42.02%,38.67%,16.98%,36.05%,33.29%,40.89%,39.00%,35.63%,42.89%,39.82%
Mistral Small 3.2,Mistral,Mistral training dataset,42.02%,38.67%,16.98%,36.05%,33.29%,40.89%,39.00%,35.63%,42.89%,39.82%
MiniMax-Text-01,MiniMax,MiniMax training dataset,45.18%,36.64%,18.09%,36.80%,34.98%,41.09%,35.76%,35.72%,41.24%,39.15%
Qwen3 8B (Reasoning),Alibaba,Qwen3 training dataset,45.18%,36.64%,18.09%,36.80%,34.98%,41.09%,35.76%,35.72%,41.24%,39.15%
Llama 4 Scout,Meta,Llama 4 training dataset,45.18%,36.64%,18.09%,36.80%,34.98%,41.09%,35.76%,35.72%,41.24%,39.15%
Llama 3.1 Instruct 405B,Meta,Llama 3.1 training dataset,45.18%,36.64%,18.09%,36.80%,34.98%,41.09%,35.76%,35.72%,41.24%,39.15%
Llama 3.3 Instruct 70B,Meta,Llama 3.3 training dataset,45.18%,36.64%,18.09%,36.80%,34.98%,41.09%,35.76%,35.72%,41.24%,39.15%
QwQ 32B-Preview,Alibaba,QwQ training dataset,45.18%,36.64%,18.09%,36.80%,34.98%,41.09%,35.76%,35.72%,41.24%,39.15%
Qwen3 VL 4B (Reasoning),Alibaba,Qwen3 VL training dataset,43.02%,39.08%,14.75%,33.32%,31.17%,39.41%,37.30%,35.96%,40.80%,37.05%
Ling-mini-2.0,InclusionAI,Ling training dataset,45.18%,36.64%,18.09%,36.80%,34.98%,41.09%,35.76%,35.72%,41.24%,39.15%
Qwen3 VL 8B Instruct,Alibaba,Qwen3 VL training dataset,43.02%,39.08%,14.75%,33.32%,31.17%,39.41%,37.30%,35.96%,40.80%,37.05%
Command A,Cohere,Cohere training dataset,43.02%,39.08%,14.75%,33.32%,31.17%,39.41%,37.30%,35.96%,40.80%,37.05%
Mistral Large 2 (Nov '24),Mistral,Mistral training dataset,43.02%,39.08%,14.75%,33.32%,31.17%,39.41%,37.30%,35.96%,40.80%,37.05%
Devstral Small (Jul '25),Mistral,Mistral training dataset,43.02%,39.08%,14.75%,33.32%,31.17%,39.41%,37.30%,35.96%,40.80%,37.05%
Exaone 4.0 1.2B (Reasoning),LG AI Research,EXAONE training dataset,43.02%,39.08%,14.75%,33.32%,31.17%,39.41%,37.30%,35.96%,40.80%,37.05%
Llama Nemotron Super 49B v1.5 (Non-reasoning),NVIDIA,Llama Nemotron training dataset,43.02%,39.08%,14.75%,33.32%,31.17%,39.41%,37.30%,35.96%,40.80%,37.05%
Qwen3 30B A3B (Non-reasoning),Alibaba,Qwen3 training dataset,43.12%,36.27%,17.59%,33.60%,31.30%,37.24%,37.41%,32.55%,40.66%,38.37%
Qwen3 32B (Non-reasoning),Alibaba,Qwen3 training dataset,43.12%,36.27%,17.59%,33.60%,31.30%,37.24%,37.41%,32.55%,40.66%,38.37%
Llama 3.1 Nemotron Nano 4B v1.1 (Reasoning),NVIDIA,Llama Nemotron training dataset,43.12%,36.27%,17.59%,33.60%,31.30%,37.24%,37.41%,32.55%,40.66%,38.37%
GLM-4.5V (Non-reasoning),Z AI,GLM-4.5 training dataset,43.12%,36.27%,17.59%,33.60%,31.30%,37.24%,37.41%,32.55%,40.66%,38.37%
Reka Flash 3,Reka AI,Reka training dataset,43.12%,36.27%,17.59%,33.60%,31.30%,37.24%,37.41%,32.55%,40.66%,38.37%
Llama 3.3 Nemotron Super 49B v1 (Non-reasoning),NVIDIA,Llama Nemotron training dataset,43.12%,36.27%,17.59%,33.60%,31.30%,37.24%,37.41%,32.55%,40.66%,38.37%
Qwen3 4B (Reasoning),Alibaba,Qwen3 training dataset,43.12%,36.27%,17.59%,33.60%,31.30%,37.24%,37.41%,32.55%,40.66%,38.37%
Llama 3.1 Tulu3 405B,Allen Institute for AI,Tulu3 training dataset,38.36%,34.95%,13.40%,35.18%,30.02%,36.42%,34.04%,35.23%,35.90%,37.44%
Qwen3 VL 4B Instruct,Alibaba,Qwen3 VL training dataset,38.36%,34.95%,13.40%,35.18%,30.02%,36.42%,34.04%,35.23%,35.90%,37.44%
Pixtral Large,Mistral,Mistral training dataset,38.36%,34.95%,13.40%,35.18%,30.02%,36.42%,34.04%,35.23%,35.90%,37.44%
Grok 2 (Dec '24),xAI,Grok training dataset,38.36%,34.95%,13.40%,35.18%,30.02%,36.42%,34.04%,35.23%,35.90%,37.44%
Hermes 4 - Llama-3.1 70B (Non-reasoning),Nous Research,Hermes 4 training dataset,36.85%,33.67%,13.13%,31.73%,28.78%,37.81%,34.30%,33.22%,39.13%,34.97%
Llama 3.1 Nemotron Instruct 70B,NVIDIA,Llama Nemotron training dataset,36.85%,33.67%,13.13%,31.73%,28.78%,37.81%,34.30%,33.22%,39.13%,34.97%
Mistral Small 3.1,Mistral,Mistral training dataset,37.00%,31.04%,16.04%,30.25%,27.53%,37.05%,30.74%,32.19%,35.25%,32.48%
Qwen3 8B (Non-reasoning),Alibaba,Qwen3 training dataset,37.00%,31.04%,16.04%,30.25%,27.53%,37.05%,30.74%,32.19%,35.25%,32.48%
Qwen2.5 Instruct 32B,Alibaba,Qwen2.5 training dataset,37.00%,31.04%,16.04%,30.25%,27.53%,37.05%,30.74%,32.19%,35.25%,32.48%
Granite 4.0 H Small,IBM,Granite training dataset,37.00%,31.04%,16.04%,30.25%,27.53%,37.05%,30.74%,32.19%,35.25%,32.48%
Phi-4,Microsoft Azure,Phi training dataset,37.00%,31.04%,16.04%,30.25%,27.53%,37.05%,30.74%,32.19%,35.25%,32.48%
Llama 3.1 Instruct 70B,Meta,Llama 3.1 training dataset,37.00%,31.04%,16.04%,30.25%,27.53%,37.05%,30.74%,32.19%,35.25%,32.48%
Qwen3 1.7B (Reasoning),Alibaba,Qwen3 training dataset,39.39%,30.58%,14.22%,28.58%,30.32%,35.85%,34.23%,32.02%,35.52%,34.61%
Mistral Large 2 (Jul '24),Mistral,Mistral training dataset,39.39%,30.58%,14.22%,28.58%,30.32%,35.85%,34.23%,32.02%,35.52%,34.61%
Gemma 3 27B Instruct,Google,Gemma 3 training dataset,39.39%,30.58%,14.22%,28.58%,30.32%,35.85%,34.23%,32.02%,35.52%,34.61%
Qwen2.5 Coder Instruct 32B,Alibaba,Qwen2.5 Coder training dataset,39.39%,30.58%,14.22%,28.58%,30.32%,35.85%,34.23%,32.02%,35.52%,34.61%
Mistral Small 3,Mistral,Mistral training dataset,35.72%,30.04%,15.05%,28.30%,25.47%,35.40%,31.91%,30.78%,32.25%,33.72%
Jamba 1.7 Large,AI21 Labs,Jamba training dataset,35.72%,30.04%,15.05%,28.30%,25.47%,35.40%,31.91%,30.78%,32.25%,33.72%
DeepSeek-V2.5 (Dec '24),DeepSeek,DeepSeek V2.5 training dataset,35.72%,30.04%,15.05%,28.30%,25.47%,35.40%,31.91%,30.78%,32.25%,33.72%
Jamba Reasoning 3B,AI21 Labs,Jamba training dataset,35.72%,30.04%,15.05%,28.30%,25.47%,35.40%,31.91%,30.78%,32.25%,33.72%
Qwen3 4B (Non-reasoning),Alibaba,Qwen3 training dataset,35.72%,30.04%,15.05%,28.30%,25.47%,35.40%,31.91%,30.78%,32.25%,33.72%
Exaone 4.0 1.2B (Non-reasoning),LG AI Research,EXAONE training dataset,34.21%,31.83%,13.79%,30.12%,26.03%,31.90%,32.03%,30.26%,35.34%,30.23%
DeepSeek-V2.5,DeepSeek,DeepSeek V2.5 training dataset,34.21%,31.83%,13.79%,30.12%,26.03%,31.90%,32.03%,30.26%,35.34%,30.23%
Gemma 3 12B Instruct,Google,Gemma 3 training dataset,34.21%,31.83%,13.79%,30.12%,26.03%,31.90%,32.03%,30.26%,35.34%,30.23%
DeepSeek R1 Distill Llama 8B,DeepSeek,DeepSeek R1 training dataset,31.63%,28.74%,12.98%,25.39%,25.10%,29.17%,27.52%,25.93%,30.49%,30.71%
Devstral Small (May '25),Mistral,Mistral training dataset,34.21%,31.83%,13.79%,30.12%,26.03%,31.90%,32.03%,30.26%,35.34%,30.23%
R1 1776,Perplexity,Perplexity training dataset,31.63%,28.74%,12.98%,25.39%,25.10%,29.17%,27.52%,25.93%,30.49%,30.71%
Llama 3.2 Instruct 90B (Vision),Meta,Llama 3.2 training dataset,31.63%,28.74%,12.98%,25.39%,25.10%,29.17%,27.52%,25.93%,30.49%,30.71%
Grok-1,xAI,Grok training dataset,32.26%,26.57%,12.54%,27.20%,26.13%,29.81%,27.72%,28.27%,31.36%,30.00%
Qwen2 Instruct 72B,Alibaba,Qwen2 training dataset,32.26%,26.57%,12.54%,27.20%,26.13%,29.81%,27.72%,28.27%,31.36%,30.00%
Solar Mini,Upstage,Solar training dataset,31.63%,28.74%,12.98%,25.39%,25.10%,29.17%,27.52%,25.93%,30.49%,30.71%
LFM2 8B A1B,Liquid AI,LFM2 training dataset,34.01%,26.87%,10.07%,25.29%,24.77%,30.19%,29.01%,23.94%,28.73%,29.86%
Gemma 2 27B,Google,Gemma 2 training dataset,34.01%,26.87%,10.07%,25.29%,24.77%,30.19%,29.01%,23.94%,28.73%,29.86%
Llama 3.1 Instruct 8B,Meta,Llama 3.1 training dataset,34.01%,26.87%,10.07%,25.29%,24.77%,30.19%,29.01%,23.94%,28.73%,29.86%
Granite 4.0 Micro,IBM,Granite training dataset,31.55%,24.26%,8.62%,24.16%,20.89%,26.87%,27.23%,24.59%,31.46%,25.78%
Phi-4 Mini Instruct,Microsoft Azure,Phi training dataset,31.55%,24.26%,8.62%,24.16%,20.89%,26.87%,27.23%,24.59%,31.46%,25.78%
DeepHermes 3 - Mistral 24B Preview (Non-reasoning),Nous Research,DeepHermes training dataset,31.55%,24.26%,8.62%,24.16%,20.89%,26.87%,27.23%,24.59%,31.46%,25.78%
Llama 3.2 Instruct 11B (Vision),Meta,Llama 3.2 training dataset,31.55%,24.26%,8.62%,24.16%,20.89%,26.87%,27.23%,24.59%,31.46%,25.78%
Gemma 3n E4B Instruct,Google,Gemma 3 training dataset,28.70%,22.99%,9.83%,21.72%,21.62%,25.27%,27.40%,23.87%,26.97%,23.82%
Granite 3.3 8B (Non-reasoning),IBM,Granite training dataset,28.70%,22.99%,9.83%,21.72%,21.62%,25.27%,27.40%,23.87%,26.97%,23.82%
Jamba 1.5 Large,AI21 Labs,Jamba training dataset,28.70%,22.99%,9.83%,21.72%,21.62%,25.27%,27.40%,23.87%,26.97%,23.82%
Jamba 1.7 Mini,AI21 Labs,Jamba training dataset,28.70%,22.99%,9.83%,21.72%,21.62%,25.27%,27.40%,23.87%,26.97%,23.82%
Gemma 3 4B Instruct,Google,Gemma 3 training dataset,28.70%,22.99%,9.83%,21.72%,21.62%,25.27%,27.40%,23.87%,26.97%,23.82%
Hermes 3 - Llama-3.1 70B,Nous Research,Hermes training dataset,28.70%,22.99%,9.83%,21.72%,21.62%,25.27%,27.40%,23.87%,26.97%,23.82%
DeepSeek-Coder-V2,DeepSeek,DeepSeek Coder training dataset,28.70%,22.99%,9.83%,21.72%,21.62%,25.27%,27.40%,23.87%,26.97%,23.82%
Qwen3 1.7B (Non-reasoning),Alibaba,Qwen3 training dataset,30.26%,26.48%,8.66%,21.80%,20.75%,27.53%,21.72%,20.41%,28.61%,25.27%
Phi-3 Medium Instruct 14B,Microsoft Azure,Phi training dataset,30.26%,26.48%,8.66%,21.80%,20.75%,27.53%,21.72%,20.41%,28.61%,25.27%
OLMo 2 32B,Allen Institute for AI,OLMo training dataset,30.26%,26.48%,8.66%,21.80%,20.75%,27.53%,21.72%,20.41%,28.61%,25.27%
Jamba 1.6 Large,AI21 Labs,Jamba training dataset,30.26%,26.48%,8.66%,21.80%,20.75%,27.53%,21.72%,20.41%,28.61%,25.27%
Qwen3 0.6B (Reasoning),Alibaba,Qwen3 training dataset,30.26%,26.48%,8.66%,21.80%,20.75%,27.53%,21.72%,20.41%,28.61%,25.27%
Granite 4.0 H 1B,IBM,Granite training dataset,30.26%,26.48%,8.66%,21.80%,20.75%,27.53%,21.72%,20.41%,28.61%,25.27%
Aya Expanse 32B,Cohere,Cohere training dataset,30.26%,26.48%,8.66%,21.80%,20.75%,27.53%,21.72%,20.41%,28.61%,25.27%
Granite 4.0 1B,IBM,Granite training dataset,30.48%,24.66%,6.78%,19.29%,21.38%,22.61%,23.78%,19.77%,24.24%,24.66%
Llama 3 Instruct 70B,Meta,Llama 3 training dataset,30.48%,24.66%,6.78%,19.29%,21.38%,22.61%,23.78%,19.77%,24.24%,24.66%
Mistral Small (Sep '24),Mistral,Mistral training dataset,30.48%,24.66%,6.78%,19.29%,21.38%,22.61%,23.78%,19.77%,24.24%,24.66%
Phi-3 Mini Instruct 3.8B,Microsoft Azure,Phi training dataset,30.48%,24.66%,6.78%,19.29%,21.38%,22.61%,23.78%,19.77%,24.24%,24.66%
Gemma 3n E4B Instruct Preview (May '25),Google,Gemma 3 training dataset,30.48%,24.66%,6.78%,19.29%,21.38%,22.61%,23.78%,19.77%,24.24%,24.66%
Phi-4 Multimodal Instruct,Microsoft Azure,Phi training dataset,26.18%,21.33%,8.80%,18.84%,16.84%,23.85%,23.86%,22.44%,22.57%,21.13%
Ministral 8B,Mistral,Mistral training dataset,26.18%,21.33%,8.80%,18.84%,16.84%,23.85%,23.86%,22.44%,22.57%,21.13%
Qwen2.5 Coder Instruct 7B,Alibaba,Qwen2.5 Coder training dataset,26.18%,21.33%,8.80%,18.84%,16.84%,23.85%,23.86%,22.44%,22.57%,21.13%
LFM2 2.6B,Liquid AI,LFM2 training dataset,26.18%,21.33%,8.80%,18.84%,16.84%,23.85%,23.86%,22.44%,22.57%,21.13%
Mixtral 8x22B Instruct,Mistral,Mixtral training dataset,26.18%,21.33%,8.80%,18.84%,16.84%,23.85%,23.86%,22.44%,22.57%,21.13%
Llama 2 Chat 7B,Meta,Llama 2 training dataset,25.56%,20.64%,6.14%,21.10%,16.78%,24.06%,21.21%,20.29%,22.23%,23.97%
Gemma 3n E2B Instruct,Google,Gemma 3 training dataset,25.56%,20.64%,6.14%,21.10%,16.78%,24.06%,21.21%,20.29%,22.23%,23.97%
Llama 3.2 Instruct 3B,Meta,Llama 3.2 training dataset,25.56%,20.64%,6.14%,21.10%,16.78%,24.06%,21.21%,20.29%,22.23%,23.97%
Qwen3 0.6B (Non-reasoning),Alibaba,Qwen3 training dataset,25.56%,20.64%,6.14%,21.10%,16.78%,24.06%,21.21%,20.29%,22.23%,23.97%
Qwen1.5 Chat 110B,Alibaba,Qwen1.5 training dataset,25.56%,20.64%,6.14%,21.10%,16.78%,24.06%,21.21%,20.29%,22.23%,23.97%
Aya Expanse 8B,Cohere,Cohere training dataset,23.05%,19.94%,5.53%,16.73%,18.41%,20.70%,20.51%,16.22%,20.56%,18.80%
LFM2 1.2B,Liquid AI,LFM2 training dataset,23.05%,19.94%,5.53%,16.73%,18.41%,20.70%,20.51%,16.22%,20.56%,18.80%
OLMo 2 7B,Allen Institute for AI,OLMo training dataset,23.05%,19.94%,5.53%,16.73%,18.41%,20.70%,20.51%,16.22%,20.56%,18.80%
Pixtral 12B (2409),Mistral,Mistral training dataset,24.39%,19.98%,5.89%,15.57%,17.34%,19.57%,21.28%,17.66%,22.87%,20.63%
Molmo 7B-D,Allen Institute for AI,Molmo training dataset,24.39%,19.98%,5.89%,15.57%,17.34%,19.57%,21.28%,17.66%,22.87%,20.63%
Llama 3.2 Instruct 1B,Meta,Llama 3.2 training dataset,24.39%,19.98%,5.89%,15.57%,17.34%,19.57%,21.28%,17.66%,22.87%,20.63%
DeepSeek R1 Distill Qwen 1.5B,DeepSeek,DeepSeek R1 training dataset,24.39%,19.98%,5.89%,15.57%,17.34%,19.57%,21.28%,17.66%,22.87%,20.63%
DeepSeek-V2-Chat,DeepSeek,DeepSeek V2 training dataset,24.39%,19.98%,5.89%,15.57%,17.34%,19.57%,21.28%,17.66%,22.87%,20.63%
Granite 4.0 H 350M,IBM,Granite training dataset,21.82%,17.28%,6.35%,13.88%,13.49%,21.59%,15.93%,13.70%,21.27%,16.72%
Gemma 2 9B,Google,Gemma 2 training dataset,21.82%,17.28%,6.35%,13.88%,13.49%,21.59%,15.93%,13.70%,21.27%,16.72%
Granite 4.0 350M,IBM,Granite training dataset,21.82%,17.28%,6.35%,13.88%,13.49%,21.59%,15.93%,13.70%,21.27%,16.72%
Arctic Instruct,Snowflake,Arctic training dataset,21.82%,17.28%,6.35%,13.88%,13.49%,21.59%,15.93%,13.70%,21.27%,16.72%
Qwen Chat 72B,Alibaba,Qwen training dataset,21.82%,17.28%,6.35%,13.88%,13.49%,21.59%,15.93%,13.70%,21.27%,16.72%
Command-R+ (Aug '24),Cohere,Cohere training dataset,21.83%,16.00%,2.57%,14.30%,11.48%,17.49%,18.06%,12.83%,17.97%,19.29%
Llama 3 Instruct 8B,Meta,Llama 3 training dataset,21.83%,16.00%,2.57%,14.30%,11.48%,17.49%,18.06%,12.83%,17.97%,19.29%
Gemma 3 1B Instruct,Google,Gemma 3 training dataset,21.83%,16.00%,2.57%,14.30%,11.48%,17.49%,18.06%,12.83%,17.97%,19.29%
DeepSeek Coder V2 Lite Instruct,DeepSeek,DeepSeek Coder training dataset,19.41%,16.81%,2.77%,12.49%,11.95%,17.97%,15.90%,13.79%,17.82%,15.77%
Codestral (May '24),Mistral,Mistral training dataset,19.41%,16.81%,2.77%,12.49%,11.95%,17.97%,15.90%,13.79%,17.82%,15.77%
Gemma 3 270M,Google,Gemma 3 training dataset,19.41%,16.81%,2.77%,12.49%,11.95%,17.97%,15.90%,13.79%,17.82%,15.77%
Llama 2 Chat 70B,Meta,Llama 2 training dataset,19.41%,16.81%,2.77%,12.49%,11.95%,17.97%,15.90%,13.79%,17.82%,15.77%
DeepSeek LLM 67B Chat (V1),DeepSeek,DeepSeek training dataset,19.41%,16.81%,2.77%,12.49%,11.95%,17.97%,15.90%,13.79%,17.82%,15.77%
Llama 2 Chat 13B,Meta,Llama 2 training dataset,19.41%,16.81%,2.77%,12.49%,11.95%,17.97%,15.90%,13.79%,17.82%,15.77%
Command-R+ (Apr '24),Cohere,Cohere training dataset,19.58%,14.06%,5.26%,11.10%,12.89%,18.83%,17.46%,12.65%,16.89%,16.64%
OpenChat 3.5 (1210),OpenChat,OpenChat training dataset,19.58%,14.06%,5.26%,11.10%,12.89%,18.83%,17.46%,12.65%,16.89%,16.64%
DBRX Instruct,Databricks,DBRX training dataset,19.58%,14.06%,5.26%,11.10%,12.89%,18.83%,17.46%,12.65%,16.89%,16.64%
Mistral NeMo,Mistral,Mistral training dataset,19.58%,14.06%,5.26%,11.10%,12.89%,18.83%,17.46%,12.65%,16.89%,16.64%
Jamba 1.5 Mini,AI21 Labs,Jamba training dataset,17.55%,13.43%,0.88%,11.48%,10.31%,16.73%,12.77%,11.28%,15.39%,16.57%
Jamba 1.6 Mini,AI21 Labs,Jamba training dataset,18.46%,11.48%,2.10%,9.50%,7.62%,14.25%,13.16%,12.05%,17.93%,14.28%
Mixtral 8x7B Instruct,Mistral,Mixtral training dataset,18.46%,11.48%,2.10%,9.50%,7.62%,14.25%,13.16%,12.05%,17.93%,14.28%
DeepHermes 3 - Llama-3.1 8B Preview (Non-reasoning),Nous Research,DeepHermes training dataset,17.22%,14.33%,1.85%,12.27%,7.19%,11.70%,11.81%,9.94%,15.26%,15.40%
Llama 65B,Meta,Llama training dataset,14.74%,11.14%,1.00%,10.00%,6.46%,10.50%,12.08%,7.71%,14.54%,10.40%
Qwen Chat 14B,Alibaba,Qwen training dataset,14.74%,11.14%,1.00%,10.00%,6.46%,10.50%,12.08%,7.71%,14.54%,10.40%
Codestral-Mamba,Mistral,Mistral training dataset,14.74%,11.14%,1.00%,10.00%,6.46%,10.50%,12.08%,7.71%,14.54%,10.40%
Mistral 7B Instruct,Mistral,Mistral training dataset,14.74%,11.14%,1.00%,10.00%,6.46%,10.50%,12.08%,7.71%,14.54%,10.40%
Command-R (Aug '24),Cohere,Cohere training dataset,14.74%,11.14%,1.00%,10.00%,6.46%,10.50%,12.08%,7.71%,14.54%,10.40%
Command-R (Mar '24),Cohere,Cohere training dataset,14.74%,11.14%,1.00%,10.00%,6.46%,10.50%,12.08%,7.71%,14.54%,10.40%
DeepSeek-OCR,DeepSeek,DeepSeek OCR training dataset,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
Kimi Linear 48B A3B Instruct,Moonshot AI,Kimi training dataset,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
Cogito v2.1 (Reasoning),Deep Cogito,Cogito training dataset,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A
